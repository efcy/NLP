import praw
import os
import csv
import sqlite3
import sys
from datetime import datetime

# --- CONFIGURATION ---
# The CSV file generated by the previous script
SUBREDDIT_CSV_FILE = "subreddits_simple.csv"
# The name for your SQLite database file
DATABASE_FILE = "reddit_data.db"
# Number of posts to fetch from each category (new, hot, controversial)
POST_LIMIT_PER_CATEGORY = 100

try:
    reddit = praw.Reddit(
        client_id=os.getenv("client_id"),
        client_secret=os.getenv("client_secret"),
        password=os.getenv("password"),
        user_agent="db_updater_script by u/yourusername", # Change to your username
        username=os.getenv("username"),
        read_only=True
    )
    print(f"Successfully authenticated as u/{reddit.user.me()}")
except Exception as e:
    print(f"Authentication failed: {e}", file=sys.stderr)
    print("Please ensure your environment variables are set correctly.", file=sys.stderr)
    sys.exit(1)


def setup_database():
    """
    Creates the SQLite database and tables if they don't exist.
    Adds a new table to track processed posts.
    """
    print(f"Connecting to and setting up database at '{DATABASE_FILE}'...")
    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()

    # Create posts table (no changes)
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS posts (
        id TEXT PRIMARY KEY,
        subreddit TEXT NOT NULL,
        title TEXT NOT NULL,
        author TEXT,
        score INTEGER,
        url TEXT,
        selftext TEXT,
        created_utc REAL NOT NULL
    )
    """)

    # Create comments table (no changes)
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS comments (
        id TEXT PRIMARY KEY,
        post_id TEXT NOT NULL,
        author TEXT,
        body TEXT,
        score INTEGER,
        created_utc REAL NOT NULL,
        FOREIGN KEY (post_id) REFERENCES posts (id) ON DELETE CASCADE
    )
    """)
    
    # NEW: Create a table to log processed post IDs.
    # This acts as our hash list to prevent re-processing.
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS processed_posts (
        post_id TEXT PRIMARY KEY
    )
    """)

    conn.commit()
    print("Database setup complete.")
    return conn

def load_processed_posts(db_conn):
    """Loads all previously processed post IDs from the database into a set for fast lookups."""
    print("Loading list of already processed posts...")
    cursor = db_conn.cursor()
    cursor.execute("SELECT post_id FROM processed_posts")
    # Use a set for O(1) average time complexity checks (very fast)
    processed_ids = {row[0] for row in cursor.fetchall()}
    print(f"Found {len(processed_ids)} posts already in the database.")
    return processed_ids

def read_subreddits_from_csv():
    """Reads the list of subreddits from the CSV file."""
    if not os.path.exists(SUBREDDIT_CSV_FILE):
        print(f"Error: Input file '{SUBREDDIT_CSV_FILE}' not found.", file=sys.stderr)
        sys.exit(1)

    with open(SUBREDDIT_CSV_FILE, mode='r', encoding='utf-8') as file:
        reader = csv.reader(file)
        next(reader) # Skip the header row
        subreddits = [row[0] for row in reader if row]
    print(f"Found {len(subreddits)} subreddits to process from '{SUBREDDIT_CSV_FILE}'.")
    return subreddits

def process_subreddit(subreddit_name, db_conn, processed_ids_set):
    """Fetches and stores posts and comments for a given subreddit, skipping duplicates."""
    cursor = db_conn.cursor()
    new_posts_found = 0

    print(f"\n--- Processing subreddit: r/{subreddit_name} ---")
    try:
        subreddit = reddit.subreddit(subreddit_name)
        categories = {
            "hot": subreddit.hot(limit=POST_LIMIT_PER_CATEGORY),
            "new": subreddit.new(limit=POST_LIMIT_PER_CATEGORY),
            "controversial": subreddit.controversial(limit=POST_LIMIT_PER_CATEGORY)
        }

        for category, listings in categories.items():
            print(f"  Fetching '{category}' posts...")
            for post in listings:
                # THE CORE LOGIC: Check if the post ID is in our set of processed posts.
                if post.id in processed_ids_set:
                    continue # Skip this post, we already have it.

                # If we reach here, the post is new to our database.
                print(f"    + New post found: {post.id} ('{post.title[:40]}...')")
                try:
                    # 1. Save post to posts table
                    cursor.execute("""
                        INSERT INTO posts (id, subreddit, title, author, score, url, selftext, created_utc)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (post.id, subreddit_name, post.title, str(post.author), post.score, post.url, post.selftext, post.created_utc))

                    # 2. Fetch and save comments
                    post.comments.replace_more(limit=0)
                    for comment in post.comments.list():
                        cursor.execute("""
                            INSERT INTO comments (id, post_id, author, body, score, created_utc)
                            VALUES (?, ?, ?, ?, ?, ?)
                        """, (comment.id, post.id, str(comment.author), comment.body, comment.score, comment.created_utc))

                    # 3. CRITICAL: Log the post_id as processed to prevent future duplication.
                    cursor.execute("INSERT INTO processed_posts (post_id) VALUES (?)", (post.id,))
                    
                    # 4. Add to the in-memory set to avoid processing again in this same run
                    processed_ids_set.add(post.id)
                    new_posts_found += 1

                except Exception as e:
                    print(f"      Error saving post {post.id} or its comments: {e}", file=sys.stderr)
        
        db_conn.commit() # Commit changes to the database after each category

    except Exception as e:
        print(f"  Could not process subreddit r/{subreddit_name}. Reason: {e}", file=sys.stderr)
    
    if new_posts_found == 0:
        print("  No new posts found for this subreddit.")
    print(f"--- Finished processing r/{subreddit_name} ---")


def main():
    """Main function to run the script."""
    db_connection = setup_database()
    processed_ids = load_processed_posts(db_connection)
    subreddits_to_process = read_subreddits_from_csv()

    for sub in subreddits_to_process:
        process_subreddit(sub, db_connection, processed_ids)

    db_connection.close()
    print("\nAll subreddits processed. Database is closed.")

if __name__ == "__main__":
    main()